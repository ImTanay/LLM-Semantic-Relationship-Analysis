{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cc8452",
   "metadata": {},
   "source": [
    "\n",
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ec19aafb-077f-4896-b1b5-c02400439bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83448d61",
   "metadata": {},
   "source": [
    "##### Add KoboldAI API endpoint URL below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "17793b39-bbd7-40e5-8434-210b43fa989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3adbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = f\"{endpoint}api/v1/generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340c14a3",
   "metadata": {},
   "source": [
    "##### Telegram Notifications for process completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1bb604ec-3303-49e6-9ac9-3dbc0635504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the variables below to enable telegram notifications\n",
    "\n",
    "# api_token = \"\" # insert telegram API token\n",
    "# chat_id = \"\" # inset the chat id for receiving notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a282422-7d0f-45e1-8e40-ba432d0c409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable the function below to start receiving notifications on telegram\n",
    "\n",
    "# def notify(text='Cell execution completed.'):\n",
    "#     requests.post('https://api.telegram.org/' + 'bot{}/sendMessage'.format(api_token), params=dict(chat_id=chat_id, text=text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a1c7ae",
   "metadata": {},
   "source": [
    "### Define the classification prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "aad1000c-e47d-4e27-a6bd-93211c14c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(topic1, topic2):\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    \n",
    "Classify the relationship between '[TOPIC-A]' and '[TOPIC-B]' by applying the following relationship definitions:\n",
    "1. '[TOPIC-A]' is-broader-than '[TOPIC-B]' if '[TOPIC-A]' is a super-category of '[TOPIC-B]', that is '[TOPIC-B]' is a type, a branch, or a specialized aspect of '[TOPIC-A]' or that '[TOPIC-B]' is a tool or a methodology mostly used in the context of '[TOPIC-A]' (e.g., car is-broader-than wheel).\n",
    "2. '[TOPIC-A]' is-narrower-than '[TOPIC-B]' if '[TOPIC-A]' is a sub-category of '[TOPIC-B]', that is '[TOPIC-A]' is a type, a branch, or a specialized aspect of '[TOPIC-B]' or that '[TOPIC-A]' is a tool or a methodology mostly used in the context of '[TOPIC-B]' (e.g., wheel is-narrower-than car).\n",
    "3. '[TOPIC-A]' is-same-as-than '[TOPIC-B]' if '[TOPIC-A]' and '[TOPIC-B]' are synonymous terms denoting an identical concept (e.g., beautiful is-same-as-than attractive), including when one is the plural form of the other (e.g., cat is-same-as-than cats).\n",
    "4. '[TOPIC-A]' is-other-than '[TOPIC-B]' if '[TOPIC-A]' and '[TOPIC-B]' either have no direct relationship or share a different kind of relationship that does not fit into the other defined relationships.\n",
    "\n",
    "Given the previous definitions, determine which one of the following statements is correct:\n",
    "1. '[TOPIC-A]' is-broader-than '[TOPIC-B]'\n",
    "2. '[TOPIC-B]' is-narrower-than '[TOPIC-A]'\n",
    "3. '[TOPIC-A]' is-narrower-than '[TOPIC-B]'\n",
    "4. '[TOPIC-B]' is-broader-than '[TOPIC-A]'\n",
    "5. '[TOPIC-A]' is-same-as-than '[TOPIC-B]'\n",
    "6. '[TOPIC-A]' is-other-than '[TOPIC-B]'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    final_prompt = prompt_template.replace(\"[TOPIC-A]\", topic1).replace(\"[TOPIC-B]\", topic2)\n",
    "\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f504910",
   "metadata": {},
   "source": [
    "### Execute LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e2ef6",
   "metadata": {},
   "source": [
    "##### Use the cell below to establish parameters for LLM and then parse the resulting output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5202af24-cfe7-4124-bd86-ad6889102fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_llm(prompt, api_url, is_final_prompt=False):\n",
    "\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"use_story\": False,\n",
    "        \"use_memory\": False,\n",
    "        \"use_authors_note\": False,\n",
    "        \"use_world_info\": False,\n",
    "        \"max_context_length\": 1600,\n",
    "        \"max_length\": 254,\n",
    "        \"rep_pen\": 1.0,\n",
    "        \"rep_pen_range\": 2048,\n",
    "        \"rep_pen_slope\": 0.7,\n",
    "        \"temperature\": 0.1,\n",
    "        \"tfs\": 1,\n",
    "        \"top_a\": 0,\n",
    "        \"top_k\": 100,\n",
    "        \"top_p\": 1,\n",
    "        \"typical\": 1,\n",
    "        \"sampler_order\": [6, 0, 1, 3, 4, 2, 5],\n",
    "        \"singleline\": False,\n",
    "        \"sampler_seed\": 42,\n",
    "        \"sampler_full_determinism\": True,\n",
    "        \"frmttriminc\": False,\n",
    "        \"frmtrmblln\": False\n",
    "    }\n",
    "\n",
    " \n",
    "    response = requests.post(api_url, json=request_body)\n",
    "\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        return \"other\", \"\"\n",
    "\n",
    "    response_data = response.json()\n",
    "    response_text = response_data.get(\"results\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "\n",
    "    if not is_final_prompt:\n",
    "        return response_text\n",
    "\n",
    "    if not response_text.strip():\n",
    "        return \"other\", \"\"\n",
    "\n",
    "\n",
    "# Does the conversion of numbers in the actual relationship\n",
    "\n",
    "    last_line = response_text.splitlines()[-1]\n",
    "    if any(tag in last_line for tag in [\"1\", \"2\", \"broader\"]):\n",
    "        return \"broader\", response_text\n",
    "    elif any(tag in last_line for tag in [\"3\", \"4\", \"narrower\"]):\n",
    "        return \"narrower\", response_text\n",
    "    elif any(tag in last_line for tag in [\"5\", \"same\", \"synonymous\"]):\n",
    "        return \"same-as\", response_text\n",
    "    elif any(tag in last_line for tag in [\"6\", \"other\", \"distinct\"]):\n",
    "        return \"other\", response_text\n",
    "    else:\n",
    "        return \"other\", response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f77d0",
   "metadata": {},
   "source": [
    "##### The function ```classify_relationship``` is responsible for classifying Research Topics and returning the output obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d88b7204-df58-4eb4-8cf4-e1df92b29966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_relationship(topic1, topic2, api_url):\n",
    "    \n",
    "    final_prompt = generate_prompt(topic1, topic2)\n",
    "\n",
    "    final_output, buffer_output = execute_llm(final_prompt, api_url, is_final_prompt=True)\n",
    "\n",
    "    return final_output, final_prompt, buffer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fa944",
   "metadata": {},
   "source": [
    "### Load Gold Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ccb4f9a-0a29-43a3-a131-9c9229a72e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_relations = f\"../dataset/GS_1000.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be0498",
   "metadata": {},
   "source": [
    "##### Use the cell below to parse ```Gold Standard``` and create a ```pandas``` dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1179a-6bc3-436e-bfd7-080462e62f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_relations, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec7ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts number of rows in dataframe\n",
    "\n",
    "num_rows = len(df)\n",
    "print(f\"Total number of rows: {num_rows}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b283d",
   "metadata": {},
   "source": [
    "### Creating ```CSV```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a53900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date and time format for dynamic file creation\n",
    "\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f7ae84",
   "metadata": {},
   "source": [
    "##### Use the cell below to store the output obtained as ```CSV``` in the folder [results](../results/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51c92a-a140-49a3-b613-90f1c024b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_relations = f\"../results/GS_1000_{current_datetime}.csv\"\n",
    "print(f\"Results will be saved in {predicted_relations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b47041",
   "metadata": {},
   "source": [
    "### Iterating over the relationships of the Gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858e528-2f7f-474b-805d-04a94f6ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(predicted_relations, mode=\"w\", newline=\"\", encoding=\"utf-8\") as output_file:\n",
    "\n",
    "# defining the headers for CSV file\n",
    "\n",
    "    fieldnames = ([\"subject\", \"object\", \"predicted_label\", \"original_label\", \"Predicted 1\", \"Predicted 2\", \"Final Prompt 1\", \"Final Prompt 2\", \"Buffer Output 1\", \"Buffer Output 2\"])\n",
    "\n",
    "\n",
    "    writer = csv.DictWriter(output_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        topic1 = row[\"subject\"]\n",
    "        topic2 = row[\"object\"]\n",
    "        target_label = row[\"original_label\"]\n",
    "\n",
    "\n",
    "        result1, prompt1, buffer_output1 = classify_relationship(topic1, topic2, api_url)\n",
    "                \n",
    "        result2, prompt2, buffer_output2 = classify_relationship(topic2, topic1, api_url)\n",
    "        \n",
    "        # empirical rules to mitigate the agreement/disagreement between the two branches of the two-way strategy\n",
    "\n",
    "        if result1 == 'broader' and result2 == 'narrower' : \n",
    "            predicted = 'broader'\n",
    "        elif result1 == 'narrower' and result2 == 'broader' : \n",
    "            predicted = 'narrower'\n",
    "        elif ( result1 == 'narrower' and result2 == 'narrower')  or (result1 == 'broader' and result2 == 'broader') : \n",
    "            if len(topic1) <= len(topic2): predicted = 'broader'\n",
    "            else : predicted = 'narrower'             \n",
    "        else :\n",
    "            if result1 == 'same-as' or result2 == 'same-as' :\n",
    "                predicted = 'same-as'\n",
    "            elif result1 == 'broader' and result2 == 'other' or  result1 == 'other' and result2 == 'narrower': \n",
    "                predicted = 'broader' \n",
    "            elif result1 == 'narrower' and result2 == 'other' or  result1 == 'other' and result2 == 'broader': \n",
    "                predicted = 'narrower'\n",
    "            else :\n",
    "                predicted = result1 \n",
    "\n",
    "        # writing obtained outputs into the CSV\n",
    "        \n",
    "        writer.writerow({\n",
    "            \"subject\": topic1,\n",
    "            \"object\": topic2,\n",
    "            \"predicted_label\": predicted or \"\",\n",
    "            \"original_label\": target_label or \"\",\n",
    "            \"Predicted 1\": result1 or \"\",\n",
    "            \"Predicted 2\": result2 or \"\",\n",
    "            \"Final Prompt 1\": prompt1 or \"\",\n",
    "            \"Final Prompt 2\": prompt2 or \"\",\n",
    "            \"Buffer Output 1\": buffer_output1 or \"\", \n",
    "            \"Buffer Output 2\": buffer_output2 or \"\"\n",
    "        })\n",
    "\n",
    "\n",
    "# notify(f\"Predictions for {input_relations} written to {predicted_relations}\") # uncomment the line to receive telegram notification on process completion\n",
    "display(HTML(f\"\"\"<a href=\"{predicted_relations}\">Click here to see the results.</a>\"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
